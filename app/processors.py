"""
å¤„ç†æ¨¡å— - å›¾ç‰‡å¤„ç†ã€PDFå¤„ç†ã€è¾¹ç•Œæ¡†ç»˜åˆ¶ç­‰
"""
import os
import io
import time
import zipfile
import traceback
from typing import List, Tuple, Optional

import numpy as np
from PIL import Image, ImageDraw, ImageFont
import fitz  # PyMuPDF

from vllm import SamplingParams
from process.image_process import DeepseekOCRProcessor
from process.ngram_norepeat import NoRepeatNGramLogitsProcessor

from .config import SIZE_CONFIGS, get_prompt
from .utils import (
    log_info, log_success, log_warning, log_error, log_progress,
    extract_grounding_references, clean_output_text, embed_images_in_markdown,
    re_match, re_match_pdf, clean_formula, is_image_file
)
from .engine import init_llm


# ============================================
# è¾¹ç•Œæ¡†ç»˜åˆ¶
# ============================================
def draw_bounding_boxes_on_image(
    image: Image.Image, 
    refs: List[Tuple[str, str, str]], 
    extract_images: bool = False
) -> Tuple[Image.Image, List[Image.Image]]:
    """
    åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†
    è¿”å›: (æ ‡æ³¨åçš„å›¾ç‰‡, è£å‰ªçš„å›¾ç‰‡åˆ—è¡¨)
    """
    img_w, img_h = image.size
    img_draw = image.copy()
    draw = ImageDraw.Draw(img_draw)
    overlay = Image.new('RGBA', img_draw.size, (0, 0, 0, 0))
    draw2 = ImageDraw.Draw(overlay)
    
    # å°è¯•åŠ è½½å­—ä½“
    try:
        font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 24)
    except Exception:
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc", 24)
        except Exception:
            font = ImageFont.load_default()
    
    crops = []
    color_map = {}
    np.random.seed(42)
    
    for ref in refs:
        label = ref[1]
        if label not in color_map:
            color_map[label] = (
                np.random.randint(50, 255), 
                np.random.randint(50, 255), 
                np.random.randint(50, 255)
            )
        color = color_map[label]
        
        try:
            coords = eval(ref[2])
        except Exception:
            continue
            
        color_a = color + (60,)
        
        for box in coords:
            try:
                x1 = int(box[0] / 999 * img_w)
                y1 = int(box[1] / 999 * img_h)
                x2 = int(box[2] / 999 * img_w)
                y2 = int(box[3] / 999 * img_h)
                
                if extract_images and label == 'image':
                    try:
                        cropped = image.crop((x1, y1, x2, y2))
                        crops.append(cropped)
                    except Exception:
                        pass
                
                width = 5 if label == 'title' else 3
                draw.rectangle([x1, y1, x2, y2], outline=color, width=width)
                draw2.rectangle([x1, y1, x2, y2], fill=color_a)
                
                text_bbox = draw.textbbox((0, 0), label, font=font)
                tw, th = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]
                ty = max(0, y1 - th - 4)
                draw.rectangle([x1, ty, x1 + tw + 4, ty + th + 4], fill=color)
                draw.text((x1 + 2, ty + 2), label, font=font, fill=(255, 255, 255))
            except Exception:
                continue
    
    img_draw = img_draw.convert('RGBA')
    img_draw = Image.alpha_composite(img_draw, overlay)
    img_draw = img_draw.convert('RGB')
    
    return img_draw, crops


# ============================================
# PDF å·¥å…·å‡½æ•°
# ============================================
def pdf_to_images_high_quality(pdf_path: str, dpi: int = 144) -> List[Image.Image]:
    """å°† PDF è½¬æ¢ä¸ºé«˜è´¨é‡å›¾ç‰‡åˆ—è¡¨"""
    images: List[Image.Image] = []
    pdf_document = fitz.open(pdf_path)
    zoom = dpi / 72.0
    matrix = fitz.Matrix(zoom, zoom)
    
    for page_num in range(pdf_document.page_count):
        page = pdf_document[page_num]
        pixmap = page.get_pixmap(matrix=matrix, alpha=False)
        Image.MAX_IMAGE_PIXELS = None
        img_data = pixmap.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        if img.mode in ("RGBA", "LA"):
            background = Image.new("RGB", img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[-1] if img.mode == "RGBA" else None)
            img = background
        images.append(img)
    
    pdf_document.close()
    return images


def get_pdf_page_count(pdf_path: str) -> int:
    """è·å– PDF é¡µæ•°"""
    if not pdf_path or not os.path.exists(pdf_path):
        return 0
    try:
        doc = fitz.open(pdf_path)
        count = doc.page_count
        doc.close()
        return count
    except Exception:
        return 0


def pdf_page_to_image(pdf_path: str, page_num: int, dpi: int = 144) -> Optional[Image.Image]:
    """å°† PDF æŒ‡å®šé¡µé¢è½¬æ¢ä¸ºå›¾ç‰‡"""
    try:
        doc = fitz.open(pdf_path)
        if page_num < 1 or page_num > doc.page_count:
            doc.close()
            return None
        
        page = doc.load_page(page_num - 1)
        zoom = dpi / 72.0
        matrix = fitz.Matrix(zoom, zoom)
        pixmap = page.get_pixmap(matrix=matrix, alpha=False)
        img = Image.open(io.BytesIO(pixmap.tobytes("png")))
        doc.close()
        return img
    except Exception:
        return None


def pil_to_pdf(pil_images: List[Image.Image], output_path: str):
    """å°† PIL å›¾ç‰‡åˆ—è¡¨ä¿å­˜ä¸º PDF"""
    import img2pdf
    if not pil_images:
        return
    
    image_bytes_list = []
    for img in pil_images:
        if img.mode != "RGB":
            img = img.convert("RGB")
        img_buffer = io.BytesIO()
        img.save(img_buffer, format="JPEG", quality=95)
        image_bytes_list.append(img_buffer.getvalue())
    
    try:
        pdf_bytes = img2pdf.convert(image_bytes_list)
        if pdf_bytes is None:
            log_error("PDF ç”Ÿæˆå¤±è´¥: img2pdf.convert è¿”å› None")
            return
        with open(output_path, "wb") as f:
            f.write(pdf_bytes)
    except Exception as e:
        log_error(f"PDF ç”Ÿæˆå¤±è´¥: {e}")


# ============================================
# å•å›¾å¤„ç†
# ============================================
def process_single_image(
    image: Image.Image,
    prompt_type: str,
    custom_prompt: str,
    model_size: str,
    crop_mode: bool,
    max_concurrency: int,
    gpu_memory_utilization: float,
    max_tokens: int,
) -> Tuple[str, str, str, Optional[Image.Image], List[Image.Image]]:
    """
    å¤„ç†å•å¼ å›¾ç‰‡
    è¿”å›: (æ¸…ç†åæ–‡æœ¬, Markdownæ¸²æŸ“, åŸå§‹è¾“å‡º, æ ‡æ³¨å›¾ç‰‡, è£å‰ªå›¾ç‰‡åˆ—è¡¨)
    """
    try:
        if image is None:
            return "æœªæ£€æµ‹åˆ°å›¾ç‰‡ï¼Œè¯·å…ˆä¸Šä¼ å›¾ç‰‡åå†ç‚¹å‡»å¤„ç†ã€‚", "", "", None, []
        
        single_start_time = time.time()
        log_info("=" * 50)
        log_info(f"ğŸ“· å¼€å§‹å•å›¾è¯†åˆ«")
        log_info("=" * 50)
        log_info(f"   è¯†åˆ«æ¨¡å¼: {prompt_type}")
        log_info(f"   æ¨¡å‹æ¡£ä½: {model_size}")
        log_info(f"   è£å‰ªæ¨¡å¼: {'å¼€å¯' if crop_mode else 'å…³é—­'}")
        log_info(f"   å›¾ç‰‡å°ºå¯¸: {image.size}")
        
        llm_local = init_llm(
            max_concurrency=max_concurrency,
            gpu_memory_utilization=gpu_memory_utilization,
            max_model_len=8192,
        )

        # è·å– prompt
        prompt, has_grounding = get_prompt(prompt_type, custom_prompt)
        
        if prompt_type == "å®šä½è¯†åˆ«" and not custom_prompt.strip():
            return "è¯·è¾“å…¥è¦å®šä½çš„æ–‡å­—", "", "", None, []
        
        log_info(f"   Prompt: {prompt[:60]}...")
        log_info(f"   Grounding: {'æ˜¯' if has_grounding else 'å¦'}")

        # è·å–å°ºå¯¸é…ç½®
        preset = SIZE_CONFIGS.get(model_size, SIZE_CONFIGS["é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰"])
        base_size = preset["base_size"]
        image_size = preset["image_size"]
        
        original_image = image.copy()
        image = image.convert("RGB")
        
        log_info(f"ğŸ”§ æ­£åœ¨é¢„å¤„ç†å›¾ç‰‡...")
        preprocess_start = time.time()
        proc = DeepseekOCRProcessor(image_size=image_size, base_size=base_size)
        image_features = proc.tokenize_with_images(
            images=[image], bos=True, eos=True, cropping=crop_mode
        )
        preprocess_time = time.time() - preprocess_start
        log_success(f"   é¢„å¤„ç†å®Œæˆ, è€—æ—¶ {preprocess_time:.2f} ç§’")

        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=40, window_size=90, whitelist_token_ids={128821, 128822}
            )
        ]

        sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=max_tokens,
            logits_processors=logits_processors,
            skip_special_tokens=False,
        )

        cache_item = {
            "prompt": prompt,
            "multi_modal_data": {"image": image_features},
        }

        log_info(f"ğŸš€ å¼€å§‹OCRæ¨ç†...")
        inference_start = time.time()
        outputs = llm_local.generate([cache_item], sampling_params=sampling_params)  # type: ignore[arg-type]
        inference_time = time.time() - inference_start
        log_success(f"   æ¨ç†å®Œæˆ, è€—æ—¶ {inference_time:.2f} ç§’")

        raw_content = outputs[0].outputs[0].text
        
        total_time = time.time() - single_start_time
        log_info("=" * 50)
        log_success(f"ğŸ“· å•å›¾è¯†åˆ«å®Œæˆï¼")
        log_info(f"   æ€»è€—æ—¶: {total_time:.2f} ç§’")
        log_info(f"   è¾“å‡ºé•¿åº¦: {len(raw_content)} å­—ç¬¦")
        log_info("=" * 50)
        
        # å¤„ç†è¾“å‡º
        cleaned_text = clean_output_text(raw_content, include_images=False, remove_labels=False)
        markdown_text = clean_output_text(raw_content, include_images=True, remove_labels=True)
        
        annotated_image = None
        cropped_images = []
        
        if has_grounding and '<|ref|>' in raw_content:
            refs = extract_grounding_references(raw_content)
            if refs:
                annotated_image, cropped_images = draw_bounding_boxes_on_image(
                    original_image, refs, extract_images=True
                )
                markdown_text = embed_images_in_markdown(markdown_text, cropped_images)
        
        return cleaned_text, markdown_text, raw_content, annotated_image, cropped_images

    except Exception as e:
        log_error(f"å•å›¾è¯†åˆ«å¤±è´¥: {str(e)}")
        error_msg = f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        return error_msg, "", "", None, []


# ============================================
# æ‰¹é‡å›¾ç‰‡å¤„ç†
# ============================================
def process_batch_images(
    uploaded_files: List[str],
    prompt_type: str,
    custom_prompt: str,
    model_size: str,
    crop_mode: bool,
    max_concurrency: int,
    gpu_memory_utilization: float,
    max_tokens: int,
) -> Tuple[str, str, List[Image.Image], List[Image.Image], str, str, Optional[str]]:
    """
    å¤„ç†æ‰¹é‡ä¸Šä¼ çš„å›¾ç‰‡
    è¿”å›: (çº¯æ–‡æœ¬, Markdownæ¸²æŸ“, è¾¹ç•Œæ¡†å›¾åˆ—è¡¨, è£å‰ªå›¾åˆ—è¡¨, åŸå§‹è¾“å‡º, çŠ¶æ€ä¿¡æ¯, ZIPæ–‡ä»¶è·¯å¾„)
    """
    try:
        if not uploaded_files:
            return "è¯·å…ˆä¸Šä¼ å›¾ç‰‡æ–‡ä»¶", "", [], [], "", "âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡æ–‡ä»¶", None
        
        batch_start_time = time.time()
        log_info("=" * 50)
        log_info(f"ğŸ“š å¼€å§‹æ‰¹é‡å¤„ç†ä»»åŠ¡")
        log_info(f"   æ–‡ä»¶æ•°é‡: {len(uploaded_files)}")
        log_info(f"   è¯†åˆ«æ¨¡å¼: {prompt_type}")
        log_info(f"   æ¨¡å‹ç²¾åº¦: {model_size}")
        log_info("=" * 50)
        
        llm_local = init_llm(
            max_concurrency=max_concurrency,
            gpu_memory_utilization=gpu_memory_utilization,
            max_model_len=8192,
        )

        # åŠ è½½å›¾ç‰‡
        images = []
        valid_paths = []
        original_images = []
        for idx, file_path in enumerate(uploaded_files):
            try:
                image = Image.open(file_path).convert("RGB")
                images.append(image)
                original_images.append(image.copy())
                valid_paths.append(file_path)
                log_progress(idx + 1, len(uploaded_files), "åŠ è½½å›¾ç‰‡")
            except Exception as e:
                log_warning(f"è·³è¿‡æ–‡ä»¶: {os.path.basename(file_path)} - {e}")

        if not images:
            return "æ²¡æœ‰å¯å¤„ç†çš„æœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶", "", [], [], "", "âš ï¸ æ²¡æœ‰å¯å¤„ç†çš„æœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶", None
        
        log_success(f"æˆåŠŸåŠ è½½ {len(images)} å¼ å›¾ç‰‡")

        # è·å– prompt
        prompt, has_grounding = get_prompt(prompt_type, custom_prompt)
        
        if prompt_type == "å®šä½è¯†åˆ«" and not custom_prompt.strip():
            return "å®šä½è¯†åˆ«æ¨¡å¼éœ€è¦è¾“å…¥è¦æŸ¥æ‰¾çš„æ–‡å­—", "", [], [], "", "âš ï¸ å®šä½è¯†åˆ«æ¨¡å¼éœ€è¦è¾“å…¥è¦æŸ¥æ‰¾çš„æ–‡å­—", None

        preset = SIZE_CONFIGS.get(model_size, SIZE_CONFIGS["é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰"])
        base_size = preset["base_size"]
        image_size = preset["image_size"]
        
        log_info(f"æ­£åœ¨é¢„å¤„ç†å›¾ç‰‡...")
        preprocess_start = time.time()
        proc = DeepseekOCRProcessor(image_size=image_size, base_size=base_size)
        batch_inputs = []
        for idx, img in enumerate(images):
            image_features = proc.tokenize_with_images(
                images=[img], bos=True, eos=True, cropping=crop_mode
            )
            batch_inputs.append({
                "prompt": prompt,
                "multi_modal_data": {"image": image_features},
            })
            if (idx + 1) % 5 == 0 or idx == len(images) - 1:
                log_progress(idx + 1, len(images), "é¢„å¤„ç†å›¾ç‰‡")
        
        preprocess_time = time.time() - preprocess_start
        log_success(f"é¢„å¤„ç†å®Œæˆï¼Œè€—æ—¶ {preprocess_time:.2f} ç§’")

        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=40, window_size=90, whitelist_token_ids={128821, 128822}
            )
        ]
        sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=max_tokens,
            logits_processors=logits_processors,
            skip_special_tokens=False,
        )

        log_info(f"ğŸš€ å¼€å§‹æ‰¹é‡æ¨ç†...")
        inference_start = time.time()
        outputs_list = llm_local.generate(batch_inputs, sampling_params=sampling_params)
        inference_time = time.time() - inference_start
        avg_time = inference_time / len(images) if images else 0
        log_success(f"æ¨ç†å®Œæˆ, æ€»è€—æ—¶ {inference_time:.2f} ç§’, å¹³å‡ {avg_time:.2f} ç§’/å¼ ")

        # ä¿å­˜ç»“æœ
        ts = time.strftime("%Y%m%d_%H%M%S")
        out_dir = os.path.join("outputs", "vllm_gradio_batch", ts)
        os.makedirs(out_dir, exist_ok=True)

        all_text = []
        all_markdown = []
        all_raw = []
        all_boxes: List[Image.Image] = []
        all_cropped: List[Image.Image] = []
        
        for idx, (output, file_path, orig_img) in enumerate(zip(outputs_list, valid_paths, original_images)):
            content = output.outputs[0].text
            base_name = os.path.basename(file_path)
            name_no_ext = os.path.splitext(base_name)[0]
            safe_name = "".join(c if c.isalnum() or c in "-_" else "_" for c in name_no_ext)

            # ä¿å­˜åŸå§‹è¾“å‡º
            with open(os.path.join(out_dir, f"{safe_name}_det.md"), "w", encoding="utf-8") as f:
                f.write(content)

            # ä¿å­˜æ¸…ç†åçš„è¾“å‡º
            content_clean = clean_output_text(content, include_images=False, remove_labels=False)
            content_markdown = clean_output_text(content, include_images=True, remove_labels=True)
            with open(os.path.join(out_dir, f"{safe_name}.md"), "w", encoding="utf-8") as f:
                f.write(content_clean)

            # æ”¶é›†æ–‡æœ¬
            all_text.append(f"## ğŸ“„ {base_name}\n\n{content_clean}")
            all_markdown.append(f"## ğŸ“„ {base_name}\n\n{content_markdown}")
            all_raw.append(f"## ğŸ“„ {base_name}\n\n{content}")
            
            # å¤„ç†è¾¹ç•Œæ¡†
            if has_grounding and '<|ref|>' in content:
                refs = extract_grounding_references(content)
                if refs:
                    annotated_img, cropped_imgs = draw_bounding_boxes_on_image(
                        orig_img, refs, extract_images=True
                    )
                    all_boxes.append(annotated_img)
                    all_cropped.extend(cropped_imgs)

        # åˆ›å»º ZIP
        zip_path = os.path.join("outputs", "vllm_gradio_batch", f"batch_result_{ts}.zip")
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, dirs, files in os.walk(out_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, out_dir)
                    zf.write(file_path, arcname)

        total_time = time.time() - batch_start_time
        log_info("=" * 50)
        log_success(f"ğŸ“š æ‰¹é‡å¤„ç†å®Œæˆï¼")
        log_info(f"   å¤„ç†å›¾ç‰‡: {len(images)} å¼ ")
        log_info(f"   æ€»è€—æ—¶: {total_time:.2f} ç§’")
        log_info(f"   å¹³å‡é€Ÿåº¦: {total_time/len(images):.2f} ç§’/å¼ ")
        log_info("=" * 50)
        
        text_output = "\n\n---\n\n".join(all_text)
        markdown_output = "\n\n---\n\n".join(all_markdown)
        raw_output = "\n\n---\n\n".join(all_raw)
        status = f"âœ… å·²å¤„ç† {len(images)} å¼ å›¾ç‰‡ | â±ï¸ æ€»è€—æ—¶: {total_time:.1f}ç§’ | âš¡ å¹³å‡: {avg_time:.2f}ç§’/å¼ "
        
        return text_output, markdown_output, all_boxes, all_cropped, raw_output, status, zip_path

    except Exception as e:
        log_error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
        error_msg = f"å¤„ç†å‡ºé”™: {str(e)}\n{traceback.format_exc()}"
        return error_msg, "", [], [], "", f"âŒ å¤„ç†å¤±è´¥: {str(e)}", None


# ============================================
# PDF å¤„ç†
# ============================================
def process_pdf_document(
    pdf_path: str,
    dpi: int,
    prompt_type: str,
    custom_prompt: str,
    model_size: str,
    crop_mode: bool,
    max_concurrency: int,
    gpu_memory_utilization: float,
    max_tokens: int,
    export_layout_pdf: bool,
    page_start: int = 1,
    page_end: int = -1,
) -> Tuple[str, str, List[Image.Image], List[Image.Image], str, str, Optional[str]]:
    """
    å¤„ç† PDF æ–‡æ¡£
    è¿”å›: (çº¯æ–‡æœ¬, Markdownæ¸²æŸ“, è¾¹ç•Œæ¡†å›¾åˆ—è¡¨, è£å‰ªå›¾åˆ—è¡¨, åŸå§‹è¾“å‡º, çŠ¶æ€ä¿¡æ¯, ZIPæ–‡ä»¶è·¯å¾„)
    """
    try:
        if not pdf_path:
            return "æœªæ£€æµ‹åˆ° PDF æ–‡ä»¶ï¼Œè¯·å…ˆä¸Šä¼ åå†ç‚¹å‡»å¤„ç†ã€‚", "", [], [], "", "âš ï¸ è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶", None
        if not os.path.exists(pdf_path):
            return f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{pdf_path}", "", [], [], "", f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨", None
        
        pdf_start_time = time.time()
        pdf_name = os.path.basename(pdf_path)
        total_pages = get_pdf_page_count(pdf_path)
        
        # å¤„ç†é¡µé¢èŒƒå›´
        if page_end <= 0 or page_end > total_pages:
            page_end = total_pages
        if page_start < 1:
            page_start = 1
        if page_start > page_end:
            page_start = page_end
        
        log_info("=" * 60)
        log_info(f"ğŸ“„ å¼€å§‹å¤„ç† PDF: {pdf_name}")
        log_info("=" * 60)
        log_info(f"   æ€»é¡µæ•°: {total_pages}")
        log_info(f"   å¤„ç†èŒƒå›´: ç¬¬ {page_start} - {page_end} é¡µ")
        log_info(f"   DPI: {dpi}")
        log_info(f"   è¯†åˆ«æ¨¡å¼: {prompt_type}")
        log_info(f"   æ¨¡å‹æ¡£ä½: {model_size}")
        
        llm_local = init_llm(
            max_concurrency=max_concurrency,
            gpu_memory_utilization=gpu_memory_utilization,
            max_model_len=8192,
        )

        # è·å– prompt
        prompt, has_grounding = get_prompt(prompt_type, custom_prompt)
        
        if prompt_type == "å®šä½è¯†åˆ«" and not custom_prompt.strip():
            return "å®šä½è¯†åˆ«æ¨¡å¼éœ€è¦è¾“å…¥è¦æŸ¥æ‰¾çš„æ–‡å­—", "", [], [], "", "âš ï¸ å®šä½è¯†åˆ«æ¨¡å¼éœ€è¦è¾“å…¥è¦æŸ¥æ‰¾çš„æ–‡å­—", None

        log_info(f"ğŸ“– æ­£åœ¨è½¬æ¢ PDF ä¸ºå›¾ç‰‡ (DPI={dpi})...")
        convert_start = time.time()
        
        # åªè½¬æ¢æŒ‡å®šé¡µé¢èŒƒå›´
        all_images = pdf_to_images_high_quality(pdf_path, dpi=dpi)
        images = all_images[page_start - 1 : page_end]
        original_images = [img.copy() for img in images]
        
        convert_time = time.time() - convert_start
        if not images:
            return "PDF ä¸­æ— å¯å¤„ç†é¡µé¢", "", [], [], "", "âš ï¸ PDF ä¸­æ— å¯å¤„ç†é¡µé¢", None
        log_success(f"   PDFè½¬æ¢å®Œæˆ: {len(images)} é¡µ, è€—æ—¶ {convert_time:.2f} ç§’")

        preset = SIZE_CONFIGS.get(model_size, SIZE_CONFIGS["é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰"])
        base_size = preset["base_size"]
        image_size = preset["image_size"]
        proc = DeepseekOCRProcessor(image_size=image_size, base_size=base_size)
        
        log_info(f"ğŸ”§ æ­£åœ¨é¢„å¤„ç† {len(images)} é¡µ...")
        preprocess_start = time.time()
        batch_inputs = []
        for idx, img in enumerate(images):
            image_features = proc.tokenize_with_images(
                images=[img], bos=True, eos=True, cropping=crop_mode
            )
            batch_inputs.append({
                "prompt": prompt,
                "multi_modal_data": {"image": image_features},
            })
            if (idx + 1) % 5 == 0 or idx == len(images) - 1:
                log_progress(idx + 1, len(images), "é¢„å¤„ç†")
        
        preprocess_time = time.time() - preprocess_start
        log_success(f"   é¢„å¤„ç†å®Œæˆ, è€—æ—¶ {preprocess_time:.2f} ç§’")

        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=20, window_size=50, whitelist_token_ids={128821, 128822}
            )
        ]
        sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=max_tokens,
            logits_processors=logits_processors,
            skip_special_tokens=False,
            include_stop_str_in_output=True,
        )

        log_info(f"ğŸš€ å¼€å§‹OCRæ¨ç† ({len(images)} é¡µ)...")
        inference_start = time.time()
        outputs_list = llm_local.generate(batch_inputs, sampling_params=sampling_params)
        inference_time = time.time() - inference_start
        avg_time = inference_time / len(images) if images else 0
        log_success(f"   æ¨ç†å®Œæˆ, æ€»è€—æ—¶ {inference_time:.2f} ç§’, å¹³å‡ {avg_time:.2f} ç§’/é¡µ")

        ts = time.strftime("%Y%m%d_%H%M%S")
        out_dir = os.path.join("outputs", "vllm_gradio_pdf", ts)
        os.makedirs(out_dir, exist_ok=True)
        os.makedirs(os.path.join(out_dir, "images"), exist_ok=True)

        log_info(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœ...")
        
        all_text = []
        all_markdown = []
        all_raw = []
        all_boxes: List[Image.Image] = []
        all_cropped: List[Image.Image] = []

        for jdx, (output, img, orig_img) in enumerate(zip(outputs_list, images, original_images)):
            content = output.outputs[0].text
            if "<ï½œendâ–ofâ–sentenceï½œ>" in content:
                content = content.replace("<ï½œendâ–ofâ–sentenceï½œ>", "")

            page_label = f"\n\n--- ğŸ“„ ç¬¬ {page_start + jdx} é¡µ ---\n\n"
            
            # åŸå§‹è¾“å‡º
            all_raw.append(f"{page_label}{content}")

            # å¤„ç†è¾¹ç•Œæ¡†å’Œè£å‰ªå›¾
            if has_grounding:
                refs = extract_grounding_references(content)
                if refs:
                    result_image, cropped_imgs = draw_bounding_boxes_on_image(orig_img, refs, extract_images=True)
                    all_boxes.append(result_image)
                    all_cropped.extend(cropped_imgs)
                
                # æ›¿æ¢å›¾ç‰‡æ ‡è®°
                _, matches_images, _ = re_match_pdf(content)
                for idx, match in enumerate(matches_images):
                    content = content.replace(
                        match,
                        f"![](images/{jdx}_{idx}.jpg)\n",
                    )
            
            # æ¸…ç†åçš„æ–‡æœ¬
            content_clean = clean_output_text(content, include_images=False, remove_labels=False)
            content_markdown = clean_output_text(content, include_images=True, remove_labels=True)
            
            all_text.append(f"{page_label}{content_clean}")
            all_markdown.append(f"{page_label}{content_markdown}")

        # ä¿å­˜æ–‡ä»¶
        base_name = os.path.basename(pdf_path)
        text_content = "".join(all_text)
        raw_content = "".join(all_raw)
        
        mmd_det_path = os.path.join(out_dir, base_name.replace(".pdf", "_det.mmd"))
        mmd_path = os.path.join(out_dir, base_name.replace(".pdf", ".mmd"))
        pdf_out_path = os.path.join(out_dir, base_name.replace(".pdf", "_layouts.pdf"))

        with open(mmd_det_path, "w", encoding="utf-8") as f:
            f.write(raw_content)
        with open(mmd_path, "w", encoding="utf-8") as f:
            f.write(text_content)

        zip_path = os.path.join("outputs", "vllm_gradio_pdf", f"pdf_result_{ts}.zip")
        
        if export_layout_pdf and all_boxes:
            log_info(f"ğŸ“Š æ­£åœ¨ç”Ÿæˆå¸ƒå±€PDF...")
            pil_to_pdf(all_boxes, pdf_out_path)
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, dirs, files in os.walk(out_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, out_dir)
                    zf.write(file_path, arcname)
        
        total_time = time.time() - pdf_start_time
        log_info("=" * 60)
        log_success(f"ğŸ“„ PDFå¤„ç†å®Œæˆï¼")
        log_info(f"   æ–‡ä»¶å: {pdf_name}")
        log_info(f"   å¤„ç†é¡µæ•°: {len(images)} é¡µ")
        log_info(f"   æ€»è€—æ—¶: {total_time:.2f} ç§’")
        log_info(f"   å¹³å‡é€Ÿåº¦: {total_time/len(images):.2f} ç§’/é¡µ")
        log_info("=" * 60)
        
        text_output = "".join(all_text)
        markdown_output = "".join(all_markdown)
        raw_output = "".join(all_raw)
        status = f"âœ… PDFå¤„ç†å®Œæˆ | ğŸ“„ {pdf_name} | ğŸ“‘ {len(images)}é¡µ | â±ï¸ {total_time:.1f}ç§’ | âš¡ {avg_time:.2f}ç§’/é¡µ"
        
        return text_output, markdown_output, all_boxes, all_cropped, raw_output, status, zip_path

    except Exception as e:
        log_error(f"PDFå¤„ç†å¤±è´¥: {str(e)}")
        error_msg = f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        return error_msg, "", [], [], "", f"âŒ PDFå¤„ç†å¤±è´¥: {str(e)}", None
