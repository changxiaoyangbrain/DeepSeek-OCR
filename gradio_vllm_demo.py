import os
import sys
import time
import json
import traceback
from datetime import datetime
import gradio as gr
from typing import Optional, List, Tuple

import torch
import gc
from PIL import Image, ImageDraw, ImageFont
import io
import re
import glob
import numpy as np
import zipfile
import shutil


# ============================================
# æ—¥å¿—è¾…åŠ©å‡½æ•°
# ============================================
def log_info(msg: str):
    """è¾“å‡ºå¸¦æ—¶é—´æˆ³çš„ INFO æ—¥å¿—"""
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts}] [INFO] {msg}")

def log_success(msg: str):
    """è¾“å‡ºå¸¦æ—¶é—´æˆ³çš„æˆåŠŸæ—¥å¿—"""
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts}] [âœ“ OK] {msg}")

def log_warning(msg: str):
    """è¾“å‡ºå¸¦æ—¶é—´æˆ³çš„è­¦å‘Šæ—¥å¿—"""
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts}] [âš  WARN] {msg}")

def log_error(msg: str):
    """è¾“å‡ºå¸¦æ—¶é—´æˆ³çš„é”™è¯¯æ—¥å¿—"""
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts}] [âœ— ERROR] {msg}")

def log_progress(current: int, total: int, task: str, extra: str = ""):
    """è¾“å‡ºè¿›åº¦æ—¥å¿—"""
    ts = datetime.now().strftime("%H:%M:%S")
    pct = (current / total * 100) if total > 0 else 0
    bar_len = 20
    filled = int(bar_len * current / total) if total > 0 else 0
    bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
    extra_str = f" | {extra}" if extra else ""
    print(f"[{ts}] [{bar}] {current}/{total} ({pct:.1f}%) {task}{extra_str}")


# Add vLLM module directory to import path
ROOT_DIR = os.path.dirname(__file__)
VLLM_DIR = os.path.join(ROOT_DIR, "DeepSeek-OCR-master", "DeepSeek-OCR-vllm")
if VLLM_DIR not in sys.path:
    sys.path.append(VLLM_DIR)

from config import (
    MODEL_PATH,
    TOKENIZER_PATH,
    PROMPT,
    CROP_MODE,
    MAX_CONCURRENCY,
)

from deepseek_ocr import DeepseekOCRForCausalLM
from vllm.model_executor.models.registry import ModelRegistry
from vllm import LLM, SamplingParams
from process.image_process import DeepseekOCRProcessor
from process.ngram_norepeat import NoRepeatNGramLogitsProcessor


llm: Optional[LLM] = None
current_engine_cfg = {
    "max_concurrency": None,
    "gpu_memory_utilization": None,
    "max_model_len": None,
}

# Model size presets (accuracy/speed tradeoff)
size_configs = {
    "æé€Ÿï¼ˆTinyï¼‰": {"base_size": 512, "image_size": 512, "crop_mode": False},
    "å¿«é€Ÿï¼ˆSmallï¼‰": {"base_size": 640, "image_size": 640, "crop_mode": False},
    "æ ‡å‡†ï¼ˆBaseï¼‰": {"base_size": 1024, "image_size": 1024, "crop_mode": False},
    "ç²¾ç»†ï¼ˆLargeï¼‰": {"base_size": 1280, "image_size": 1280, "crop_mode": False},
    "é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰": {"base_size": 1024, "image_size": 640, "crop_mode": True},
}


def _ensure_offline_env():
    os.environ.setdefault("HF_HUB_OFFLINE", "1")
    os.environ.setdefault("TRANSFORMERS_OFFLINE", "1")
    os.environ.setdefault("HF_HUB_DISABLE_TELEMETRY", "1")
    os.environ.setdefault("HF_HUB_ENABLE_HF_TRANSFER", "1")


def _setup_cuda_env():
    os.environ.setdefault("VLLM_USE_V1", "0")
    os.environ.setdefault("CUDA_VISIBLE_DEVICES", "0")
    try:
        if getattr(torch.version, "cuda", None) == "11.8":
            for p in [
                "/usr/local/cuda-11.8/bin/ptxas",
                "/usr/local/cuda/bin/ptxas",
            ]:
                if os.path.exists(p):
                    os.environ["TRITON_PTXAS_PATH"] = p
                    break
    except Exception:
        pass


def init_llm(
    max_concurrency: int,
    gpu_memory_utilization: float,
    max_model_len: int = 8192,
    force_reinit: bool = False,
):
    global llm, current_engine_cfg

    if (
        llm is not None
        and not force_reinit
        and current_engine_cfg.get("max_concurrency") == max_concurrency
        and current_engine_cfg.get("gpu_memory_utilization") == gpu_memory_utilization
        and current_engine_cfg.get("max_model_len") == max_model_len
    ):
        return llm

    # Cleanup previous engine if reconfiguring
    if llm is not None:
        try:
            llm.sleep()
        except Exception:
            pass
        try:
            del llm
        except Exception:
            pass
        llm = None
        try:
            torch.cuda.empty_cache()
        except Exception:
            pass
        try:
            if hasattr(torch.cuda, "ipc_collect"):
                torch.cuda.ipc_collect()
        except Exception:
            pass
        try:
            gc.collect()
        except Exception:
            pass
        try:
            torch.cuda.synchronize()
        except Exception:
            pass
        time.sleep(0.5)

    _ensure_offline_env()
    _setup_cuda_env()

    ModelRegistry.register_model("DeepseekOCRForCausalLM", DeepseekOCRForCausalLM)

    try:
        llm = LLM(
            model=MODEL_PATH,
            tokenizer=TOKENIZER_PATH,
            hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
            block_size=256,
            enforce_eager=False,
            trust_remote_code=False,
            max_model_len=max_model_len,
            swap_space=0,
            max_num_seqs=max_concurrency,
            tensor_parallel_size=1,
            gpu_memory_utilization=gpu_memory_utilization,
            disable_mm_preprocessor_cache=True,
        )
    except AssertionError as ae:
        # Retry once after aggressive cleanup to handle vLLM memory profiling assertion
        try:
            torch.cuda.empty_cache()
        except Exception:
            pass
        try:
            if hasattr(torch.cuda, "ipc_collect"):
                torch.cuda.ipc_collect()
        except Exception:
            pass
        try:
            gc.collect()
        except Exception:
            pass
        time.sleep(0.5)
        llm = LLM(
            model=MODEL_PATH,
            tokenizer=TOKENIZER_PATH,
            hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
            block_size=256,
            enforce_eager=False,
            trust_remote_code=False,
            max_model_len=max_model_len,
            swap_space=0,
            max_num_seqs=max_concurrency,
            tensor_parallel_size=1,
            gpu_memory_utilization=gpu_memory_utilization,
            disable_mm_preprocessor_cache=True,
        )

    current_engine_cfg = {
        "max_concurrency": max_concurrency,
        "gpu_memory_utilization": gpu_memory_utilization,
        "max_model_len": max_model_len,
    }
    return llm


def process_image(
    image: Image.Image,
    prompt_type: str,
    custom_prompt: str,
    model_size: str,
    crop_mode: bool,
    max_concurrency: int,
    gpu_memory_utilization: float,
    max_tokens: int,
):
    try:
        # Guard empty input
        if image is None:
            return "æœªæ£€æµ‹åˆ°å›¾ç‰‡ï¼Œè¯·å…ˆä¸Šä¼ å›¾ç‰‡åå†ç‚¹å‡»å¤„ç†ã€‚"
        
        single_start_time = time.time()
        log_info("=" * 50)
        log_info(f"ğŸ“· å¼€å§‹å•å›¾è¯†åˆ«")
        log_info("=" * 50)
        log_info(f"   è¯†åˆ«æ¨¡å¼: {prompt_type}")
        log_info(f"   æ¨¡å‹æ¡£ä½: {model_size}")
        log_info(f"   è£å‰ªæ¨¡å¼: {'å¼€å¯' if crop_mode else 'å…³é—­'}")
        log_info(f"   å›¾ç‰‡å°ºå¯¸: {image.size}")
        
        llm_local = init_llm(
            max_concurrency=max_concurrency,
            gpu_memory_utilization=gpu_memory_utilization,
            max_model_len=8192,
        )

        # æ ¹æ®å®˜æ–¹æ–‡æ¡£è®¾ç½® prompt
        # æ–‡æ¡£: <image>\n<|grounding|>Convert the document to markdown.
        # çº¯æ–‡å­—: <image>\nFree OCR.
        # å…¶ä»–å›¾ç‰‡: <image>\n<|grounding|>OCR this image.
        # å›¾è¡¨: <image>\nParse the figure.
        # é€šç”¨æè¿°: <image>\nDescribe this image in detail.
        if prompt_type == "è‡ªç”±è¯†åˆ«":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "Markdownè½¬æ¢":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "å›¾ç‰‡OCR":
            prompt = "<image>\n<|grounding|>OCR this image. "
        elif prompt_type == "å›¾è¡¨è§£æ":
            prompt = "<image>\nParse the figure. "
        elif prompt_type == "å›¾åƒæè¿°":
            prompt = "<image>\nDescribe this image in detail. "
        elif prompt_type == "è‡ªå®šä¹‰":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "
        
        log_info(f"   Prompt: {prompt[:50]}...")

        # Apply size preset
        preset = size_configs.get(model_size, size_configs["é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰"])
        base_size = preset["base_size"]
        image_size = preset["image_size"]
        # Use current checkbox for cropping (updated by preset change)
        image = image.convert("RGB")
        
        log_info(f"ğŸ”§ æ­£åœ¨é¢„å¤„ç†å›¾ç‰‡...")
        preprocess_start = time.time()
        proc = DeepseekOCRProcessor(image_size=image_size, base_size=base_size)
        image_features = proc.tokenize_with_images(
            images=[image], bos=True, eos=True, cropping=crop_mode
        )
        preprocess_time = time.time() - preprocess_start
        log_success(f"   é¢„å¤„ç†å®Œæˆ, è€—æ—¶ {preprocess_time:.2f} ç§’")

        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=40, window_size=90, whitelist_token_ids={128821, 128822}
            )
        ]

        sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=max_tokens,
            logits_processors=logits_processors,
            skip_special_tokens=False,
        )

        cache_item = {
            "prompt": prompt,
            "multi_modal_data": {"image": image_features},
        }

        log_info(f"ğŸš€ å¼€å§‹OCRæ¨ç†...")
        inference_start = time.time()
        outputs = llm_local.generate(
            [cache_item], sampling_params=sampling_params
        )
        inference_time = time.time() - inference_start
        log_success(f"   æ¨ç†å®Œæˆ, è€—æ—¶ {inference_time:.2f} ç§’")

        content = outputs[0].outputs[0].text
        
        # æ¸…ç†ç»“æœï¼šç§»é™¤ç»“æŸæ ‡è®°
        if "<ï½œendâ–ofâ–sentenceï½œ>" in content:
            content = content.replace("<ï½œendâ–ofâ–sentenceï½œ>", "")
        
        total_time = time.time() - single_start_time
        log_info("=" * 50)
        log_success(f"ğŸ“· å•å›¾è¯†åˆ«å®Œæˆï¼")
        log_info(f"   æ€»è€—æ—¶: {total_time:.2f} ç§’")
        log_info(f"   è¾“å‡ºé•¿åº¦: {len(content)} å­—ç¬¦")
        log_info("=" * 50)
        
        return content

    except Exception as e:
        log_error(f"å•å›¾è¯†åˆ«å¤±è´¥: {str(e)}")
        return f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"

def clean_formula(text: str) -> str:
    formula_pattern = r"\\\[(.*?)\\\]"

    def process_formula(match):
        formula = match.group(1)
        formula = re.sub(r"\\quad\s*\([^)]*\)", "", formula)
        formula = formula.strip()
        return r"\[" + formula + r"\]"

    cleaned_text = re.sub(formula_pattern, process_formula, text)
    return cleaned_text

def re_match(text: str) -> Tuple[List[Tuple[str, str, str]], List[str]]:
    pattern = r"(<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>)"
    matches = re.findall(pattern, text, re.DOTALL)
    mathes_other = []
    for a_match in matches:
        mathes_other.append(a_match[0])
    return matches, mathes_other

def re_match_pdf(text: str) -> Tuple[List[Tuple[str, str, str]], List[str], List[str]]:
    pattern = r"(<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>)"
    matches = re.findall(pattern, text, re.DOTALL)
    mathes_image = []
    mathes_other = []
    for a_match in matches:
        if '<|ref|>image<|/ref|>' in a_match[0]:
            mathes_image.append(a_match[0])
        else:
            mathes_other.append(a_match[0])
    return matches, mathes_image, mathes_other


def _is_image(path: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„å›¾ç‰‡æ ¼å¼"""
    return os.path.splitext(path)[1].lower() in {".jpg", ".jpeg", ".png", ".webp", ".bmp", ".tiff", ".tif"}


def _list_images_in_dir(dir_path: str) -> list:
    """
    åˆ—å‡ºç›®å½•ä¸­æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼Œå…¼å®¹ä¸­æ–‡è·¯å¾„ã€‚
    ä½¿ç”¨ os.listdir ä»£æ›¿ glob.glob ä»¥é¿å…ä¸­æ–‡è·¯å¾„é—®é¢˜ã€‚
    """
    if not os.path.isdir(dir_path):
        return []
    try:
        files = os.listdir(dir_path)
        images = []
        for f in files:
            full_path = os.path.join(dir_path, f)
            if os.path.isfile(full_path) and _is_image(full_path):
                images.append(full_path)
        return sorted(images)
    except Exception:
        return []


def process_batch_upload(
    uploaded_files: List[str],
    prompt_type: str,
    custom_prompt: str,
    model_size: str,
    crop_mode: bool,
    max_concurrency: int,
    gpu_memory_utilization: float,
    max_tokens: int,
):
    """å¤„ç†ä¸Šä¼ çš„å¤šå¼ å›¾ç‰‡ï¼ˆæ”¯æŒè¿œç¨‹å®¢æˆ·ç«¯ï¼‰"""
    try:
        if not uploaded_files:
            return "è¯·å…ˆä¸Šä¼ å›¾ç‰‡æ–‡ä»¶", "", None
        
        batch_start_time = time.time()
        log_info("=" * 50)
        log_info(f"ğŸ“š å¼€å§‹æ‰¹é‡å¤„ç†ä»»åŠ¡")
        log_info(f"   æ–‡ä»¶æ•°é‡: {len(uploaded_files)}")
        log_info(f"   è¯†åˆ«æ¨¡å¼: {prompt_type}")
        log_info(f"   æ¨¡å‹ç²¾åº¦: {model_size}")
        log_info(f"   æ™ºèƒ½è£å‰ª: {'æ˜¯' if crop_mode else 'å¦'}")
        log_info("=" * 50)
        
        log_info("æ­£åœ¨åˆå§‹åŒ–æ¨ç†å¼•æ“...")
        llm_local = init_llm(
            max_concurrency=max_concurrency,
            gpu_memory_utilization=gpu_memory_utilization,
            max_model_len=8192,
        )
        log_success("æ¨ç†å¼•æ“å°±ç»ª")

        log_info("æ­£åœ¨åŠ è½½å›¾ç‰‡...")
        images = []
        valid_paths = []
        for idx, file_path in enumerate(uploaded_files):
            try:
                image = Image.open(file_path).convert("RGB")
                images.append(image)
                valid_paths.append(file_path)
                log_progress(idx + 1, len(uploaded_files), "åŠ è½½å›¾ç‰‡", os.path.basename(file_path))
            except Exception as e:
                log_warning(f"è·³è¿‡æ–‡ä»¶: {os.path.basename(file_path)} - {e}")

        if not images:
            return "æ²¡æœ‰å¯å¤„ç†çš„æœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶", "", None
        
        log_success(f"æˆåŠŸåŠ è½½ {len(images)} å¼ å›¾ç‰‡")

        # æ ¹æ®å®˜æ–¹æ–‡æ¡£è®¾ç½® prompt
        if prompt_type == "è‡ªç”±è¯†åˆ«":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "Markdownè½¬æ¢":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "å›¾ç‰‡OCR":
            prompt = "<image>\n<|grounding|>OCR this image. "
        elif prompt_type == "å›¾è¡¨è§£æ":
            prompt = "<image>\nParse the figure. "
        elif prompt_type == "å›¾åƒæè¿°":
            prompt = "<image>\nDescribe this image in detail. "
        elif prompt_type == "è‡ªå®šä¹‰":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "

        preset = size_configs.get(model_size, size_configs["é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰"])
        base_size = preset["base_size"]
        image_size = preset["image_size"]
        
        log_info(f"æ­£åœ¨é¢„å¤„ç†å›¾ç‰‡ (base_size={base_size}, image_size={image_size})...")
        preprocess_start = time.time()
        proc = DeepseekOCRProcessor(image_size=image_size, base_size=base_size)
        batch_inputs = []
        for idx, img in enumerate(images):
            image_features = proc.tokenize_with_images(
                images=[img], bos=True, eos=True, cropping=crop_mode
            )
            cache_item = {
                "prompt": prompt,
                "multi_modal_data": {"image": image_features},
            }
            batch_inputs.append(cache_item)
            if (idx + 1) % 5 == 0 or idx == len(images) - 1:
                log_progress(idx + 1, len(images), "é¢„å¤„ç†å›¾ç‰‡")
        preprocess_time = time.time() - preprocess_start
        log_success(f"é¢„å¤„ç†å®Œæˆï¼Œè€—æ—¶ {preprocess_time:.2f} ç§’")

        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=40, window_size=90, whitelist_token_ids={128821, 128822}
            )
        ]

        sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=max_tokens,
            logits_processors=logits_processors,
            skip_special_tokens=False,
        )

        log_info(f"ğŸš€ å¼€å§‹æ‰¹é‡æ¨ç† ({len(batch_inputs)} å¼ å›¾ç‰‡)...")
        inference_start = time.time()
        outputs_list = llm_local.generate(batch_inputs, sampling_params=sampling_params)
        inference_time = time.time() - inference_start
        avg_time = inference_time / len(batch_inputs) if batch_inputs else 0
        log_success(f"æ¨ç†å®Œæˆï¼Œæ€»è€—æ—¶ {inference_time:.2f} ç§’ï¼Œå¹³å‡ {avg_time:.2f} ç§’/å¼ ")

        ts = time.strftime("%Y%m%d_%H%M%S")
        out_dir = os.path.join("outputs", "vllm_gradio_batch", ts)
        os.makedirs(out_dir, exist_ok=True)

        log_info("æ­£åœ¨ä¿å­˜è¯†åˆ«ç»“æœ...")
        preview_texts = []
        for idx, (output, file_path) in enumerate(zip(outputs_list, valid_paths)):
            content = output.outputs[0].text
            base_name = os.path.basename(file_path)
            name_no_ext = os.path.splitext(base_name)[0]
            # é¿å…æ–‡ä»¶åå†²çªï¼Œæ·»åŠ åºå·
            safe_name = f"{idx+1:03d}_{name_no_ext}"

            mmd_det_path = os.path.join(out_dir, f"{safe_name}_det.md")
            with open(mmd_det_path, "w", encoding="utf-8") as afile:
                afile.write(content)

            content_clean = clean_formula(content)
            matches_ref, mathes_other = re_match(content_clean)
            for a_match_other in mathes_other:
                content_clean = (
                    content_clean.replace(a_match_other, "")
                    .replace("\\n\\n\\n\\n", "\\n\\n")
                    .replace("\\n\\n\\n", "\\n\\n")
                    .replace("<center>", "")
                    .replace("</center>", "")
                )

            mmd_path = os.path.join(out_dir, f"{safe_name}.md")
            with open(mmd_path, "w", encoding="utf-8") as afile:
                afile.write(content_clean)

            if len(preview_texts) < 3:
                preview_texts.append(f"## {base_name}\n\n" + content_clean[:2000])

        # åˆ›å»º zip æ–‡ä»¶ä¾›ä¸‹è½½
        zip_path = os.path.join("outputs", "vllm_gradio_batch", f"batch_result_{ts}.zip")
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, dirs, files in os.walk(out_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, out_dir)
                    zf.write(file_path, arcname)

        total_time = time.time() - batch_start_time
        log_info("=" * 50)
        log_success(f"ğŸ“š æ‰¹é‡å¤„ç†å®Œæˆï¼")
        log_info(f"   å¤„ç†å›¾ç‰‡: {len(images)} å¼ ")
        log_info(f"   æ€»è€—æ—¶: {total_time:.2f} ç§’")
        log_info(f"   å¹³å‡é€Ÿåº¦: {total_time/len(images):.2f} ç§’/å¼ ")
        log_info(f"   è¾“å‡ºç›®å½•: {out_dir}")
        log_info("=" * 50)
        
        return f"âœ… å·²å¤„ç† {len(images)} å¼ å›¾ç‰‡\nâ±ï¸ æ€»è€—æ—¶: {total_time:.1f} ç§’\nğŸ“ ç»“æœä¿å­˜åˆ°: {out_dir}", "\n\n".join(preview_texts), zip_path

    except Exception as e:
        log_error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
        return f"å¤„ç†å‡ºé”™: {str(e)}\n{traceback.format_exc()}", "", None


def process_batch(
    dir_path: str,
    prompt_type: str,
    custom_prompt: str,
    model_size: str,
    crop_mode: bool,
    max_concurrency: int,
    gpu_memory_utilization: float,
    max_tokens: int,
):
    """å¤„ç†æœåŠ¡å™¨æœ¬åœ°ç›®å½•ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰"""
    try:
        llm_local = init_llm(
            max_concurrency=max_concurrency,
            gpu_memory_utilization=gpu_memory_utilization,
            max_model_len=8192,
        )

        # ä½¿ç”¨å…¼å®¹ä¸­æ–‡è·¯å¾„çš„æ–¹æ³•åˆ—å‡ºå›¾ç‰‡
        images_path = _list_images_in_dir(dir_path)
        if not images_path:
            return f"ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼ˆæ”¯æŒ jpg/png/webp/bmp/tiffï¼‰ï¼š{dir_path}", ""

        images = []
        for image_path in images_path:
            try:
                image = Image.open(image_path).convert("RGB")
                images.append(image)
            except Exception as e:
                print(f"skip file: {image_path} due to error: {e}")

        # æ ¹æ®å®˜æ–¹æ–‡æ¡£è®¾ç½® prompt
        if prompt_type == "è‡ªç”±è¯†åˆ«":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "Markdownè½¬æ¢":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "å›¾ç‰‡OCR":
            prompt = "<image>\n<|grounding|>OCR this image. "
        elif prompt_type == "å›¾è¡¨è§£æ":
            prompt = "<image>\nParse the figure. "
        elif prompt_type == "å›¾åƒæè¿°":
            prompt = "<image>\nDescribe this image in detail. "
        elif prompt_type == "è‡ªå®šä¹‰":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "

        preset = size_configs.get(model_size, size_configs["é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰"])
        base_size = preset["base_size"]
        image_size = preset["image_size"]
        proc = DeepseekOCRProcessor(image_size=image_size, base_size=base_size)
        batch_inputs = []
        for img in images:
            image_features = proc.tokenize_with_images(
                images=[img], bos=True, eos=True, cropping=crop_mode
            )
            cache_item = {
                "prompt": prompt,
                "multi_modal_data": {"image": image_features},
            }
            batch_inputs.append(cache_item)

        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=40, window_size=90, whitelist_token_ids={128821, 128822}
            )
        ]

        sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=max_tokens,
            logits_processors=logits_processors,
            skip_special_tokens=False,
        )

        outputs_list = llm_local.generate(batch_inputs, sampling_params=sampling_params)

        ts = time.strftime("%Y%m%d_%H%M%S")
        out_dir = os.path.join("outputs", "vllm_gradio_batch", ts)
        os.makedirs(out_dir, exist_ok=True)

        preview_texts = []
        for output, image_path in zip(outputs_list, images_path):
            content = output.outputs[0].text
            base_name = os.path.basename(image_path)
            name_no_ext = os.path.splitext(base_name)[0]

            mmd_det_path = os.path.join(out_dir, f"{name_no_ext}_det.md")
            with open(mmd_det_path, "w", encoding="utf-8") as afile:
                afile.write(content)

            content_clean = clean_formula(content)
            matches_ref, mathes_other = re_match(content_clean)
            for a_match_other in mathes_other:
                content_clean = (
                    content_clean.replace(a_match_other, "")
                    .replace("\\n\\n\\n\\n", "\\n\\n")
                    .replace("\\n\\n\\n", "\\n\\n")
                    .replace("<center>", "")
                    .replace("</center>", "")
                )

            mmd_path = os.path.join(out_dir, f"{name_no_ext}.md")
            with open(mmd_path, "w", encoding="utf-8") as afile:
                afile.write(content_clean)

            if len(preview_texts) < 3:
                preview_texts.append(f"## {base_name}\n\n" + content_clean[:2000])

        return f"å·²å†™å…¥ {len(images_path)} ä¸ªç»“æœåˆ°: {out_dir}", "\n\n".join(preview_texts)

    except Exception as e:
        import traceback
        return f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}", ""

def pdf_to_images_high_quality(pdf_path: str, dpi: int = 144, image_format: str = "PNG") -> List[Image.Image]:
    import fitz
    images: List[Image.Image] = []
    pdf_document = fitz.open(pdf_path)
    zoom = dpi / 72.0
    matrix = fitz.Matrix(zoom, zoom)
    for page_num in range(pdf_document.page_count):
        page = pdf_document[page_num]
        pixmap = page.get_pixmap(matrix=matrix, alpha=False)
        Image.MAX_IMAGE_PIXELS = None
        img_data = pixmap.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        if img.mode in ("RGBA", "LA"):
            background = Image.new("RGB", img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[-1] if img.mode == "RGBA" else None)
            img = background
        images.append(img)
    pdf_document.close()
    return images

def pil_to_pdf_img2pdf(pil_images: List[Image.Image], output_path: str):
    import img2pdf
    if not pil_images:
        return
    image_bytes_list = []
    for img in pil_images:
        if img.mode != "RGB":
            img = img.convert("RGB")
        img_buffer = io.BytesIO()
        img.save(img_buffer, format="JPEG", quality=95)
        img_bytes = img_buffer.getvalue()
        image_bytes_list.append(img_bytes)
    try:
        pdf_bytes = img2pdf.convert(image_bytes_list)
        with open(output_path, "wb") as f:
            f.write(pdf_bytes)
    except Exception as e:
        print(f"error: {e}")

def extract_coordinates_and_label(ref_text: Tuple[str, str, str], image_width: int, image_height: int):
    try:
        label_type = ref_text[1]
        cor_list = eval(ref_text[2])
    except Exception as e:
        print(e)
        return None
    return (label_type, cor_list)

def draw_bounding_boxes(image: Image.Image, refs: List[Tuple[str, str, str]], jdx: int, save_dir: str):
    image_width, image_height = image.size
    img_draw = image.copy()
    draw = ImageDraw.Draw(img_draw)
    overlay = Image.new("RGBA", img_draw.size, (0, 0, 0, 0))
    draw2 = ImageDraw.Draw(overlay)
    font = ImageFont.load_default()
    img_idx = 0
    os.makedirs(os.path.join(save_dir, "images"), exist_ok=True)
    for i, ref in enumerate(refs):
        try:
            result = extract_coordinates_and_label(ref, image_width, image_height)
            if result:
                label_type, points_list = result
                color = (
                    np.random.randint(0, 200),
                    np.random.randint(0, 200),
                    np.random.randint(0, 255),
                )
                color_a = color + (20,)
                for points in points_list:
                    x1, y1, x2, y2 = points
                    x1 = int(x1 / 999 * image_width)
                    y1 = int(y1 / 999 * image_height)
                    x2 = int(x2 / 999 * image_width)
                    y2 = int(y2 / 999 * image_height)
                    if label_type == "image":
                        try:
                            cropped = image.crop((x1, y1, x2, y2))
                            cropped.save(os.path.join(save_dir, "images", f"{jdx}_{img_idx}.jpg"))
                        except Exception as e:
                            print(e)
                        img_idx += 1
                    try:
                        if label_type == "title":
                            draw.rectangle([x1, y1, x2, y2], outline=color, width=4)
                            draw2.rectangle(
                                [x1, y1, x2, y2], fill=color_a, outline=(0, 0, 0, 0), width=1
                            )
                        else:
                            draw.rectangle([x1, y1, x2, y2], outline=color, width=2)
                            draw2.rectangle(
                                [x1, y1, x2, y2], fill=color_a, outline=(0, 0, 0, 0), width=1
                            )
                        text_x = x1
                        text_y = max(0, y1 - 15)
                        text_bbox = draw.textbbox((0, 0), label_type, font=font)
                        text_width = text_bbox[2] - text_bbox[0]
                        text_height = text_bbox[3] - text_bbox[1]
                        draw.rectangle(
                            [text_x, text_y, text_x + text_width, text_y + text_height],
                            fill=(255, 255, 255, 30),
                        )
                        draw.text((text_x, text_y), label_type, font=font, fill=color)
                    except Exception:
                        pass
        except Exception:
            continue
    img_draw.paste(overlay, (0, 0), overlay)
    return img_draw

def process_pdf(
    pdf_path: str,
    dpi: int,
    prompt_type: str,
    custom_prompt: str,
    model_size: str,
    crop_mode: bool,
    max_concurrency: int,
    gpu_memory_utilization: float,
    max_tokens: int,
    export_layout_pdf: bool,
):
    try:
        # Guard empty input
        if not pdf_path:
            return "æœªæ£€æµ‹åˆ° PDF æ–‡ä»¶ï¼Œè¯·å…ˆä¸Šä¼ åå†ç‚¹å‡»å¤„ç†ã€‚", "", None
        if isinstance(pdf_path, str) and not os.path.exists(pdf_path):
            return f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{pdf_path}", "", None
        
        pdf_start_time = time.time()
        pdf_name = os.path.basename(pdf_path)
        log_info("=" * 60)
        log_info(f"ğŸ“„ å¼€å§‹å¤„ç† PDF: {pdf_name}")
        log_info("=" * 60)
        log_info(f"   DPI: {dpi}")
        log_info(f"   è¯†åˆ«æ¨¡å¼: {prompt_type}")
        log_info(f"   æ¨¡å‹æ¡£ä½: {model_size}")
        log_info(f"   è£å‰ªæ¨¡å¼: {'å¼€å¯' if crop_mode else 'å…³é—­'}")
        log_info(f"   æœ€å¤§Token: {max_tokens}")
        log_info(f"   å¯¼å‡ºå¸ƒå±€PDF: {'æ˜¯' if export_layout_pdf else 'å¦'}")
        
        llm_local = init_llm(
            max_concurrency=max_concurrency,
            gpu_memory_utilization=gpu_memory_utilization,
            max_model_len=8192,
        )

        # æ ¹æ®å®˜æ–¹æ–‡æ¡£è®¾ç½® prompt
        if prompt_type == "è‡ªç”±è¯†åˆ«":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "Markdownè½¬æ¢":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "å›¾ç‰‡OCR":
            prompt = "<image>\n<|grounding|>OCR this image. "
        elif prompt_type == "å›¾è¡¨è§£æ":
            prompt = "<image>\nParse the figure. "
        elif prompt_type == "å›¾åƒæè¿°":
            prompt = "<image>\nDescribe this image in detail. "
        elif prompt_type == "è‡ªå®šä¹‰":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "

        log_info(f"ğŸ“– æ­£åœ¨è½¬æ¢ PDF ä¸ºå›¾ç‰‡ (DPI={dpi})...")
        convert_start = time.time()
        images = pdf_to_images_high_quality(pdf_path, dpi=dpi)
        convert_time = time.time() - convert_start
        if not images:
            return "PDF ä¸­æ— å¯å¤„ç†é¡µé¢", "", None
        log_success(f"   PDFè½¬æ¢å®Œæˆ: {len(images)} é¡µ, è€—æ—¶ {convert_time:.2f} ç§’")

        preset = size_configs.get(model_size, size_configs["é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰"])
        base_size = preset["base_size"]
        image_size = preset["image_size"]
        proc = DeepseekOCRProcessor(image_size=image_size, base_size=base_size)
        
        log_info(f"ğŸ”§ æ­£åœ¨é¢„å¤„ç† {len(images)} é¡µ...")
        preprocess_start = time.time()
        batch_inputs = []
        for idx, img in enumerate(images):
            image_features = proc.tokenize_with_images(
                images=[img], bos=True, eos=True, cropping=crop_mode
            )
            cache_item = {
                "prompt": prompt,
                "multi_modal_data": {"image": image_features},
            }
            batch_inputs.append(cache_item)
            if (idx + 1) % 5 == 0 or idx == len(images) - 1:
                log_progress(idx + 1, len(images), "é¢„å¤„ç†")
        preprocess_time = time.time() - preprocess_start
        log_success(f"   é¢„å¤„ç†å®Œæˆ, è€—æ—¶ {preprocess_time:.2f} ç§’")

        logits_processors = [
            NoRepeatNGramLogitsProcessor(
                ngram_size=20, window_size=50, whitelist_token_ids={128821, 128822}
            )
        ]
        sampling_params = SamplingParams(
            temperature=0.0,
            max_tokens=max_tokens,
            logits_processors=logits_processors,
            skip_special_tokens=False,
            include_stop_str_in_output=True,
        )

        log_info(f"ğŸš€ å¼€å§‹OCRæ¨ç† ({len(images)} é¡µ)...")
        inference_start = time.time()
        outputs_list = llm_local.generate(batch_inputs, sampling_params=sampling_params)
        inference_time = time.time() - inference_start
        avg_time = inference_time / len(images) if images else 0
        log_success(f"   æ¨ç†å®Œæˆ, æ€»è€—æ—¶ {inference_time:.2f} ç§’, å¹³å‡ {avg_time:.2f} ç§’/é¡µ")

        ts = time.strftime("%Y%m%d_%H%M%S")
        out_dir = os.path.join("outputs", "vllm_gradio_pdf", ts)
        os.makedirs(out_dir, exist_ok=True)
        os.makedirs(os.path.join(out_dir, "images"), exist_ok=True)

        log_info(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœ...")
        contents_det = ""
        contents = ""
        draw_images: List[Image.Image] = []

        jdx = 0
        for output, img in zip(outputs_list, images):
            content = output.outputs[0].text
            if "<ï½œendâ–ofâ–sentenceï½œ>" in content:
                content = content.replace("<ï½œendâ–ofâ–sentenceï½œ>", "")

            page_num = f"\n<--- Page Split --->"
            contents_det += content + f"\n{page_num}\n"

            image_draw = img.copy()
            matches_ref, matches_images, _ = re_match_pdf(content)
            result_image = draw_bounding_boxes(image_draw, matches_ref, jdx, out_dir)
            draw_images.append(result_image)

            for idx, a_match in enumerate(matches_images):
                content = content.replace(
                    a_match,
                    f"![](images/" + str(jdx) + "_" + str(idx) + ".jpg)\n",
                )
            content = (
                content.replace("\\coloneqq", ":=")
                .replace("\\eqqcolon", "=:")
                .replace("\n\n\n\n", "\n\n")
                .replace("\n\n\n", "\n\n")
            )

            contents += content + f"\n{page_num}\n"
            jdx += 1

        base_name = os.path.basename(pdf_path)
        mmd_det_path = os.path.join(out_dir, base_name.replace(".pdf", "_det.mmd"))
        mmd_path = os.path.join(out_dir, base_name.replace(".pdf", ".mmd"))
        pdf_out_path = os.path.join(out_dir, base_name.replace(".pdf", "_layouts.pdf"))

        with open(mmd_det_path, "w", encoding="utf-8") as afile:
            afile.write(contents_det)
        with open(mmd_path, "w", encoding="utf-8") as afile:
            afile.write(contents)

        # åˆ›å»º zip æ–‡ä»¶ä¾›ä¸‹è½½
        zip_path = os.path.join("outputs", "vllm_gradio_pdf", f"pdf_result_{ts}.zip")
        
        if export_layout_pdf:
            log_info(f"ğŸ“Š æ­£åœ¨ç”Ÿæˆå¸ƒå±€PDF...")
            pil_to_pdf_img2pdf(draw_images, pdf_out_path)
        
        # æ‰“åŒ…æ‰€æœ‰ç»“æœåˆ° zip
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, dirs, files in os.walk(out_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, out_dir)
                    zf.write(file_path, arcname)
        
        total_time = time.time() - pdf_start_time
        log_info("=" * 60)
        log_success(f"ğŸ“„ PDFå¤„ç†å®Œæˆï¼")
        log_info(f"   æ–‡ä»¶å: {pdf_name}")
        log_info(f"   å¤„ç†é¡µæ•°: {len(images)} é¡µ")
        log_info(f"   æ€»è€—æ—¶: {total_time:.2f} ç§’")
        log_info(f"   å¹³å‡é€Ÿåº¦: {total_time/len(images):.2f} ç§’/é¡µ")
        log_info(f"   è¾“å‡ºç›®å½•: {out_dir}")
        log_info("=" * 60)
        
        return contents, contents_det, zip_path

    except Exception as e:
        log_error(f"PDFå¤„ç†å¤±è´¥: {str(e)}")
        return f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}", "", None



def create_demo():
    # è‡ªå®šä¹‰ CSS æ ·å¼ - é•¿å°å…»ç…§æŠ¤æ™ºèƒ½èµ„æºæ•°å­—åŒ–å¹³å°ä¸»é¢˜
    custom_css = """
    /* å…¨å±€æ ·å¼ */
    .gradio-container {
        font-family: 'Microsoft YaHei', 'PingFang SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif !important;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        min-height: 100vh;
    }
    
    /* ä¸»å®¹å™¨ */
    .main {
        background: rgba(255, 255, 255, 0.95) !important;
        border-radius: 20px !important;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.15) !important;
        margin: 20px !important;
        padding: 30px !important;
    }
    
    /* é¡µé¢å¤´éƒ¨æ ·å¼ */
    .header-banner {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 50%, #1e3c72 100%);
        padding: 40px 30px;
        border-radius: 16px;
        margin-bottom: 25px;
        text-align: center;
        box-shadow: 0 10px 40px rgba(30, 60, 114, 0.3);
        position: relative;
        overflow: hidden;
    }
    
    .header-banner::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: url("data:image/svg+xml,%3Csvg width='60' height='60' viewBox='0 0 60 60' xmlns='http://www.w3.org/2000/svg'%3E%3Cg fill='none' fill-rule='evenodd'%3E%3Cg fill='%23ffffff' fill-opacity='0.05'%3E%3Ccircle cx='30' cy='30' r='4'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E");
        pointer-events: none;
    }
    
    .header-banner h1 {
        color: #ffffff !important;
        font-size: 2.5em !important;
        font-weight: 700 !important;
        margin: 0 0 15px 0 !important;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        letter-spacing: 3px;
    }
    
    .header-banner p {
        color: rgba(255, 255, 255, 0.9) !important;
        font-size: 1.1em !important;
        margin: 8px 0 !important;
        line-height: 1.6;
    }
    
    .header-banner .subtitle {
        display: inline-block;
        background: rgba(255, 255, 255, 0.15);
        padding: 8px 20px;
        border-radius: 25px;
        margin-top: 10px;
        backdrop-filter: blur(10px);
    }
    
    /* æç¤ºæ¡†æ ·å¼ */
    .tips-box {
        background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%);
        border-left: 4px solid #4caf50;
        border-radius: 0 12px 12px 0;
        padding: 15px 20px;
        margin-bottom: 15px;
        box-shadow: 0 4px 15px rgba(76, 175, 80, 0.15);
    }
    
    .tips-box .tips-title {
        color: #2e7d32 !important;
        margin: 0 0 10px 0 !important;
        font-size: 1em;
        font-weight: 600;
    }
    
    .tips-box .tips-title strong {
        color: #2e7d32 !important;
    }
    
    .tips-box .tips-content {
        color: #1b5e20 !important;
        margin: 6px 0 !important;
        font-size: 0.9em;
        line-height: 1.5;
    }
    
    /* é€‰é¡¹å¡æ ·å¼ */
    .tabs > .tab-nav {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%) !important;
        border-radius: 12px !important;
        padding: 5px !important;
        margin-bottom: 20px !important;
    }
    
    .tabs > .tab-nav > button {
        border-radius: 8px !important;
        font-weight: 600 !important;
        transition: all 0.3s ease !important;
        padding: 12px 24px !important;
        color: #1e3c72 !important;
        background: transparent !important;
    }
    
    .tabs > .tab-nav > button:hover {
        background: rgba(30, 60, 114, 0.1) !important;
        color: #1e3c72 !important;
    }
    
    .tabs > .tab-nav > button.selected {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%) !important;
        color: white !important;
        box-shadow: 0 4px 15px rgba(30, 60, 114, 0.3) !important;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .primary {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%) !important;
        border: none !important;
        border-radius: 10px !important;
        font-weight: 600 !important;
        font-size: 1.05em !important;
        padding: 12px 28px !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 4px 15px rgba(30, 60, 114, 0.3) !important;
    }
    
    .primary:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 6px 25px rgba(30, 60, 114, 0.4) !important;
    }
    
    button.secondary {
        background: linear-gradient(135deg, #6c757d 0%, #495057 100%) !important;
        border: none !important;
        border-radius: 8px !important;
        color: white !important;
        transition: all 0.3s ease !important;
    }
    
    button.secondary:hover {
        transform: translateY(-1px) !important;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2) !important;
    }
    
    /* è¾“å…¥æ¡†æ ·å¼ */
    textarea, input[type="text"] {
        border: 2px solid #e9ecef !important;
        border-radius: 10px !important;
        transition: all 0.3s ease !important;
    }
    
    textarea:focus, input[type="text"]:focus {
        border-color: #2a5298 !important;
        box-shadow: 0 0 0 3px rgba(42, 82, 152, 0.15) !important;
    }
    
    /* æ»‘å—æ ·å¼ */
    input[type="range"] {
        accent-color: #2a5298 !important;
    }
    
    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */
    .file-upload {
        border: 2px dashed #2a5298 !important;
        border-radius: 12px !important;
        background: rgba(42, 82, 152, 0.03) !important;
        transition: all 0.3s ease !important;
    }
    
    .file-upload:hover {
        background: rgba(42, 82, 152, 0.08) !important;
        border-color: #1e3c72 !important;
    }
    
    /* å›¾ç‰‡ä¸Šä¼ åŒºåŸŸ */
    .image-upload {
        border-radius: 12px !important;
        overflow: hidden;
    }
    
    /* Accordion æ‰‹é£ç´æ ·å¼ */
    .accordion {
        border: 1px solid #e9ecef !important;
        border-radius: 12px !important;
        overflow: hidden;
    }
    
    .accordion > .label-wrap {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%) !important;
        padding: 12px 16px !important;
    }
    
    /* è®¾ç½®é¢æ¿ */
    .settings-panel {
        background: linear-gradient(135deg, #f8f9fa 0%, #ffffff 100%);
        border-radius: 16px;
        padding: 20px;
        border: 1px solid #e9ecef;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.05);
    }
    
    /* éšè— Gradio åŸç”Ÿ footer */
    footer.svelte-1rjryqp,
    footer.svelte-mpyp5e,
    .gradio-container > footer,
    footer[class*="svelte"],
    .built-with {
        display: none !important;
    }
    
    /* é¡µè„šæ ·å¼ */
    .footer {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 25px;
        border-radius: 12px;
        margin-top: 30px;
        text-align: center;
    }
    
    .footer p {
        margin: 5px 0 !important;
        color: rgba(255, 255, 255, 0.9) !important;
    }
    
    .footer .copyright {
        font-size: 0.95em;
        opacity: 0.9;
    }
    
    .footer .tech-info {
        font-size: 0.85em;
        opacity: 0.7;
        margin-top: 10px !important;
    }
    
    /* å•é€‰æŒ‰é’®ç»„ */
    .radio-group {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 10px;
    }
    
    /* å¤é€‰æ¡† */
    input[type="checkbox"] {
        accent-color: #2a5298 !important;
    }
    
    /* çŠ¶æ€æ–‡æœ¬æ¡† */
    .status-box textarea {
        background: #f8f9fa !important;
        font-family: 'Consolas', 'Monaco', monospace !important;
    }
    
    /* å“åº”å¼è°ƒæ•´ */
    @media (max-width: 768px) {
        .header-banner h1 {
            font-size: 1.8em !important;
        }
        .main {
            margin: 10px !important;
            padding: 15px !important;
        }
    }
    
    /* åŠ¨ç”»æ•ˆæœ */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .gradio-container > * {
        animation: fadeIn 0.5s ease-out;
    }
    """
    
    # Gradio 6.0+ ä½¿ç”¨ launch(css=...) è€Œä¸æ˜¯ Blocks(css=...)
    with gr.Blocks(title="é•¿å°å…»ç…§æŠ¤æ™ºèƒ½èµ„æºæ•°å­—åŒ–å¹³å°") as demo:
        # é¡µé¢å¤´éƒ¨ Banner
        gr.HTML(
            """
            <div class="header-banner">
                <h1>ğŸ¥ é•¿å°å…»ç…§æŠ¤æ™ºèƒ½èµ„æºæ•°å­—åŒ–å¹³å°</h1>
                <p>æ™ºèƒ½æ–‡æ¡£è¯†åˆ« Â· é«˜æ•ˆæ•°å­—åŒ–è½¬æ¢ Â· ä¸“ä¸šç…§æŠ¤çŸ¥è¯†ç®¡ç†</p>
                <div class="subtitle">ğŸ“„ æ”¯æŒå›¾ç‰‡OCR Â· æ‰¹é‡å¤„ç† Â· PDFæ™ºèƒ½è§£æ</div>
            </div>
            """
        )
        
        # æç¤ºä¿¡æ¯
        gr.HTML(
            """
            <div class="tips-box">
                <p class="tips-title">ğŸ’¡ <strong>ä½¿ç”¨æç¤º</strong></p>
                <p class="tips-content">â€¢ <b>Markdownè½¬æ¢</b>ï¼šæ–‡æ¡£/è®ºæ–‡è¯†åˆ«ï¼Œä¿ç•™ç‰ˆé¢ç»“æ„ã€è¡¨æ ¼ã€å…¬å¼ï¼ˆæ¨èï¼‰</p>
                <p class="tips-content">â€¢ <b>è‡ªç”±è¯†åˆ«</b>ï¼šçº¯æ–‡å­—æå–ï¼Œä¸å«å¸ƒå±€ä¿¡æ¯</p>
                <p class="tips-content">â€¢ <b>å›¾ç‰‡OCR</b>ï¼šé€šç”¨å›¾ç‰‡ä¸­çš„æ–‡å­—è¯†åˆ«</p>
                <p class="tips-content">â€¢ <b>å›¾è¡¨è§£æ</b>ï¼šä¸“é—¨è§£æå›¾è¡¨ã€æµç¨‹å›¾ç­‰</p>
                <p class="tips-content">â€¢ <b>å›¾åƒæè¿°</b>ï¼šè·å–å›¾ç‰‡çš„è¯¦ç»†æè¿°</p>
            </div>
            """
        )
        
        # è®¾ç½®åŒºåŸŸæ ‡é¢˜
        gr.Markdown("### âš™ï¸ é€šç”¨è®¾ç½®")

        with gr.Row():
            with gr.Column(scale=1):
                prompt_type = gr.Radio(
                    choices=[
                        "Markdownè½¬æ¢",
                        "è‡ªç”±è¯†åˆ«",
                        "å›¾ç‰‡OCR",
                        "å›¾è¡¨è§£æ",
                        "å›¾åƒæè¿°",
                        "è‡ªå®šä¹‰",
                    ],
                    value="Markdownè½¬æ¢",
                    label="ğŸ“ è¯†åˆ«æ¨¡å¼",
                    info="æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©ï¼šæ–‡æ¡£ç”¨Markdownã€çº¯æ–‡å­—ç”¨è‡ªç”±è¯†åˆ«ã€å›¾è¡¨ç”¨å›¾è¡¨è§£æ"
                )
                custom_prompt = gr.Textbox(
                    label="è‡ªå®šä¹‰æŒ‡ä»¤ï¼ˆé€‰æ‹©ã€Œè‡ªå®šä¹‰ã€æ—¶ç”Ÿæ•ˆï¼‰",
                    placeholder="ä¾‹å¦‚: Locate <|ref|>å…³é”®è¯<|/ref|> in the image.",
                    lines=2,
                    visible=False,
                )
            with gr.Column(scale=1):
                crop_mode = gr.Checkbox(
                    label="ğŸ“ å¯ç”¨æ™ºèƒ½è£å‰ª",
                    value=bool(CROP_MODE),
                    info="é€‚ç”¨äºå¤§å°ºå¯¸æ–‡æ¡£å›¾ç‰‡"
                )
                model_size = gr.Radio(
                    choices=[
                        "æé€Ÿï¼ˆTinyï¼‰",
                        "å¿«é€Ÿï¼ˆSmallï¼‰",
                        "æ ‡å‡†ï¼ˆBaseï¼‰",
                        "ç²¾ç»†ï¼ˆLargeï¼‰",
                        "é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰",
                    ],
                    value="æ ‡å‡†ï¼ˆBaseï¼‰",
                    label="ğŸ¯ æ¨¡å‹ç²¾åº¦",
                    info="é«˜è¾¾æ¨¡å¼å¹³è¡¡é€Ÿåº¦ä¸ç²¾åº¦ï¼Œæ¨èä½¿ç”¨"
                )
            with gr.Column(scale=1):
                with gr.Accordion("âš¡ é«˜çº§å‚æ•°", open=False):
                    # åŠ¨æ€è§£æå¹¶å‘æ»‘æ¡çš„é»˜è®¤å€¼ä¸ä¸Šé™ï¼Œé¿å…é»˜è®¤å€¼è¶Šç•Œ
                    try:
                        _default_concurrency = int(MAX_CONCURRENCY) if MAX_CONCURRENCY else 12
                    except Exception:
                        _default_concurrency = 12
                    _concurrency_max = max(16, _default_concurrency)
                    _concurrency_default = min(_default_concurrency, _concurrency_max)
                    max_concurrency = gr.Slider(
                        minimum=1,
                        maximum=_concurrency_max,
                        step=1,
                        value=_concurrency_default,
                        label="å¹¶å‘æ•°é‡",
                        info="å»ºè®®æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´"
                    )
                    gpu_memory_utilization = gr.Slider(
                        minimum=0.5,
                        maximum=0.98,
                        step=0.01,
                        value=0.85,
                        label="æ˜¾å­˜åˆ©ç”¨ç‡",
                        info="å»ºè®®ä¿æŒåœ¨0.85å·¦å³"
                    )
                    max_tokens = gr.Slider(
                        minimum=256,
                        maximum=16384,
                        step=512,
                        value=16384,
                        label="æœ€å¤§ç”Ÿæˆé•¿åº¦",
                        info="æ–‡æ¡£è¾ƒé•¿æ—¶è¯·å¢å¤§æ­¤å€¼"
                    )
                    with gr.Row():
                        restart_btn = gr.Button("â™»ï¸ é‡å¯å¼•æ“", variant="secondary")
                        estimate_btn = gr.Button("ğŸ§® ä¼°ç®—å¹¶å‘", variant="secondary")
                    restart_service_btn = gr.Button("ğŸ”„ é‡å¯æœåŠ¡", variant="secondary")
                    engine_status = gr.Textbox(
                        label="å¼•æ“çŠ¶æ€",
                        value="âœ… å·²å°±ç»ª",
                        lines=2,
                        interactive=False,
                    )

        with gr.Tabs():
            with gr.Tab("ğŸ“· å•å›¾è¯†åˆ«"):
                with gr.Row():
                    with gr.Column(scale=1):
                        image_input = gr.Image(
                            label="ğŸ“¤ ä¸Šä¼ å›¾ç‰‡ï¼ˆæ”¯æŒæ‹–æ‹½/ç²˜è´´ï¼‰",
                            type="pil",
                            sources=["upload", "clipboard"],
                        )
                        process_btn_single = gr.Button("ğŸš€ å¼€å§‹è¯†åˆ«", variant="primary")
                    with gr.Column(scale=1):
                        output_text_single = gr.Textbox(
                            label="ğŸ“„ è¯†åˆ«ç»“æœ",
                            lines=20,
                            max_lines=30,
                        )

            with gr.Tab("ğŸ“š æ‰¹é‡å¤„ç†"):
                gr.HTML(
                    '''
                    <div style="background:linear-gradient(135deg,#e8f4fd,#d4e9f7);padding:15px 20px;border-radius:10px;margin-bottom:15px;border-left:4px solid #1e3c72;">
                        <p style="margin:0;"><span style="color:#1e3c72 !important;font-weight:bold;font-size:1.1em;">ğŸ“‚ æ‰¹é‡è¯†åˆ«æ¨¡å¼</span> <span style="color:#333;">- æ”¯æŒåŒæ—¶ä¸Šä¼ å¤šå¼ å›¾ç‰‡è¿›è¡Œæ‰¹å¤„ç†</span></p>
                        <p style="margin:5px 0 0 0;color:#555;font-size:0.9em;">æ”¯æŒæ ¼å¼: JPG, PNG, WebP, BMP, TIFF</p>
                    </div>
                    '''
                )
                with gr.Row():
                    with gr.Column(scale=1):
                        batch_files = gr.File(
                            label="ğŸ“¤ ä¸Šä¼ å›¾ç‰‡ï¼ˆå¯å¤šé€‰ï¼‰",
                            file_count="multiple",
                            file_types=["image"],
                            type="filepath",
                        )
                        process_btn_batch = gr.Button("ğŸš€ å¼€å§‹æ‰¹é‡è¯†åˆ«", variant="primary")
                    with gr.Column(scale=1):
                        batch_outdir_text = gr.Textbox(
                            label="ğŸ“Š å¤„ç†çŠ¶æ€",
                            lines=2,
                            interactive=False,
                        )
                        batch_download = gr.File(
                            label="ğŸ“¥ ä¸‹è½½è¯†åˆ«ç»“æœï¼ˆZIPå‹ç¼©åŒ…ï¼‰",
                            interactive=False,
                        )
                        batch_preview_text = gr.Textbox(
                            label="ğŸ‘€ ç»“æœé¢„è§ˆï¼ˆå‰3é¡¹ï¼‰",
                            lines=15,
                            max_lines=25,
                        )

            with gr.Tab("ğŸ“‘ PDFè§£æ"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.HTML(
                            '''
                            <div style="background:linear-gradient(135deg,#fff3e0,#ffe0b2);padding:15px 20px;border-radius:10px;margin-bottom:15px;border-left:4px solid #ff9800;">
                                <p style="margin:0;"><span style="color:#e65100 !important;font-weight:bold;font-size:1.1em;">ğŸ“‘ PDFæ™ºèƒ½è§£æ</span></p>
                                <p style="margin:5px 0 0 0;color:#555;font-size:0.9em;">è‡ªåŠ¨æå–PDFå†…å®¹å¹¶è½¬æ¢ä¸ºMarkdownæ ¼å¼</p>
                            </div>
                            '''
                        )
                        pdf_file = gr.File(
                            label="ğŸ“¤ ä¸Šä¼ PDFæ–‡ä»¶",
                            file_types=[".pdf"],
                            type="filepath",
                        )
                        pdf_dpi = gr.Slider(
                            minimum=72,
                            maximum=288,
                            step=12,
                            value=144,
                            label="ğŸ” æ¸²æŸ“ç²¾åº¦ï¼ˆDPIï¼‰",
                            info="æ•°å€¼è¶Šé«˜ç²¾åº¦è¶Šå¥½ï¼Œä½†é€Ÿåº¦è¶Šæ…¢"
                        )
                        export_layout_pdf = gr.Checkbox(
                            label="ğŸ“ å¯¼å‡ºå¸ƒå±€åˆ†æPDF",
                            value=False,
                            info="ç”Ÿæˆå¸¦æ ‡æ³¨çš„å¸ƒå±€åˆ†ææ–‡æ¡£ï¼ˆå¤„ç†è¾ƒæ…¢ï¼‰"
                        )
                        process_btn_pdf = gr.Button("ğŸš€ å¼€å§‹è§£æPDF", variant="primary")
                    with gr.Column(scale=1):
                        pdf_mmd_text = gr.Textbox(
                            label="ğŸ“„ Markdownè¾“å‡º",
                            lines=20,
                            max_lines=30,
                        )
                        pdf_det_text = gr.Textbox(
                            label="ğŸ” è¯¦ç»†æ£€æµ‹ç»“æœ",
                            lines=20,
                            max_lines=30,
                        )
                        pdf_layouts_file = gr.File(
                            label="ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœï¼ˆZIPå‹ç¼©åŒ…ï¼‰",
                            interactive=False,
                        )

        def update_prompt_visibility(choice):
            return gr.update(visible=(choice == "è‡ªå®šä¹‰"))

        prompt_type.change(
            fn=update_prompt_visibility,
            inputs=[prompt_type],
            outputs=[custom_prompt],
        )

        # å½“é€‰æ‹©å°ºå¯¸é¢„è®¾æ—¶ï¼Œæ›´æ–°è£å‰ªæ¨èå€¼
        def apply_size_preset(choice):
            preset = size_configs.get(choice, size_configs["é«˜è¾¾æ¨¡å¼ï¼ˆæ¨èï¼‰"])
            return gr.update(value=preset["crop_mode"]) 

        model_size.change(
            fn=apply_size_preset,
            inputs=[model_size],
            outputs=[crop_mode],
        )

        # è§¦å‘æœåŠ¡çº§é‡å¯ï¼ˆwatch æ¨¡å¼ä¸‹é€šè¿‡å†™å…¥ä¿¡å·æ–‡ä»¶è§¦å‘ï¼‰
        def trigger_service_restart():
            try:
                sig_path = os.path.join(ROOT_DIR, "watch_restart.json")
                import json
                ts = time.time()
                with open(sig_path, "w", encoding="utf-8") as f:
                    json.dump({"restart_at": ts}, f)
                return "å·²è§¦å‘æœåŠ¡é‡å¯ï¼ˆwatchï¼‰ï¼Œè¯·ç¨ååˆ·æ–°é¡µé¢ã€‚"
            except Exception as e:
                return f"è§¦å‘å¤±è´¥ï¼š{e}"

        # åŸºäº GPU æ˜¾å­˜ä¸ max_tokens çš„å¹¶å‘ä¼°ç®—
        def estimate_concurrency_action(gmu: float, max_toks: int):
            try:
                if torch.cuda.is_available():
                    free_b, total_b = torch.cuda.mem_get_info()
                    total_gb = total_b / (1024 ** 3)
                    free_gb = free_b / (1024 ** 3)
                    # æœ‰æ•ˆå¯ç”¨æ˜¾å­˜ï¼šè€ƒè™‘ slider çš„ gmuï¼Œå°½é‡ä¸è¶…å½“å‰ç©ºé—²
                    effective_gb = max(min(total_gb * gmu, free_gb) - 1.0, 1.0)
                else:
                    effective_gb = 8.0
            except Exception:
                try:
                    props = torch.cuda.get_device_properties(0)
                    total_gb = props.total_memory / (1024 ** 3)
                    effective_gb = max(total_gb * gmu - 1.0, 1.0)
                except Exception:
                    effective_gb = 8.0

            # ç»éªŒä¼°ç®—ï¼š8192 tokens æ—¶æ¯å¹¶å‘çº¦ ~800MBï¼›çº¿æ€§éš max_tokens å˜åŒ–
            per_seq_mb = 800.0 * max(1.0, float(max_toks) / 8192.0)
            est = int(max(1, (effective_gb * 1024.0) / per_seq_mb))
            try:
                cfg_max = int(MAX_CONCURRENCY) if MAX_CONCURRENCY else 16
            except Exception:
                cfg_max = 16
            new_max = max(16, cfg_max, est)
            est = min(est, new_max)
            return gr.update(value=est, maximum=new_max)

        estimate_btn.click(
            fn=estimate_concurrency_action,
            inputs=[gpu_memory_utilization, max_tokens],
            outputs=[max_concurrency],
        )

        # å¼ºåˆ¶é‡å¯å¼•æ“ï¼ˆæ¸…ç†æ˜¾å­˜å¹¶æŒ‰å½“å‰å‚æ•°é‡å»ºï¼‰
        def restart_engine_action(max_conc: int, gmu: float):
            try:
                _ensure_offline_env()
                _setup_cuda_env()
                # force_reinit è§¦å‘æ¸…ç†é€»è¾‘
                _ = init_llm(
                    max_concurrency=max_conc,
                    gpu_memory_utilization=gmu,
                    max_model_len=8192,
                    force_reinit=True,
                )
                return "å¼•æ“å·²é‡å¯ï¼šå¹¶å‘=%dï¼Œæ˜¾å­˜åˆ©ç”¨ç‡=%.2fï¼Œmax_len=8192" % (max_conc, gmu)
            except Exception as e:
                import traceback
                return f"é‡å¯å¤±è´¥ï¼š{str(e)}\n\n{traceback.format_exc()}"

        restart_btn.click(
            fn=restart_engine_action,
            inputs=[max_concurrency, gpu_memory_utilization],
            outputs=[engine_status],
        )

        restart_service_btn.click(
            fn=trigger_service_restart,
            inputs=[],
            outputs=[engine_status],
        )

        process_btn_single.click(
            fn=process_image,
            inputs=[
                image_input,
                prompt_type,
                custom_prompt,
                model_size,
                crop_mode,
                max_concurrency,
                gpu_memory_utilization,
                max_tokens,
            ],
            outputs=[output_text_single],
        )

        process_btn_batch.click(
            fn=process_batch_upload,
            inputs=[
                batch_files,
                prompt_type,
                custom_prompt,
                model_size,
                crop_mode,
                max_concurrency,
                gpu_memory_utilization,
                max_tokens,
            ],
            outputs=[batch_outdir_text, batch_preview_text, batch_download],
        )

        process_btn_pdf.click(
            fn=process_pdf,
            inputs=[
                pdf_file,
                pdf_dpi,
                prompt_type,
                custom_prompt,
                model_size,
                crop_mode,
                max_concurrency,
                gpu_memory_utilization,
                max_tokens,
                export_layout_pdf,
            ],
            outputs=[pdf_mmd_text, pdf_det_text, pdf_layouts_file],
        )
        
        # é¡µè„šç‰ˆæƒä¿¡æ¯
        gr.HTML(
            """
            <div class="footer">
                <p style="font-size:1.1em;font-weight:600;">ğŸ¥ é•¿å°å…»ç…§æŠ¤æ™ºèƒ½èµ„æºæ•°å­—åŒ–å¹³å°</p>
                <p class="copyright">Â© 2025 æµ·å—é•¿å°å…»æ™ºèƒ½ç§‘æŠ€ ç‰ˆæƒæ‰€æœ‰</p>
                <p class="tech-info">æŠ€æœ¯æ”¯æŒ: DeepSeek-OCR Â· vLLM é«˜æ€§èƒ½æ¨ç†å¼•æ“</p>
            </div>
            """
        )

    return demo, custom_css


if __name__ == "__main__":
    _ensure_offline_env()
    _setup_cuda_env()
    # å¯é€‰å¯åŠ¨é¢„çƒ­ï¼šè®¾ç½®ç¯å¢ƒå˜é‡ WARMUP_ON_START=1 å¯ç”¨
    def warmup_engine_on_start():
        if os.environ.get("WARMUP_ON_START", "0") != "1":
            print("[INFO] è·³è¿‡æ¨¡å‹é¢„çƒ­ï¼ˆè®¾ç½® WARMUP_ON_START=1 å¯å¯ç”¨ï¼‰")
            return
        
        print("=" * 50)
        print("ğŸš€ æ­£åœ¨é¢„çƒ­æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        print("=" * 50)
        
        try:
            _default_concurrency = int(MAX_CONCURRENCY) if MAX_CONCURRENCY else 8
        except Exception:
            _default_concurrency = 8
        
        gmu = 0.85
        print(f"[INFO] åŠ è½½é…ç½®: å¹¶å‘={_default_concurrency}, æ˜¾å­˜åˆ©ç”¨ç‡={gmu}, max_len=8192")
        
        try:
            llm_local = init_llm(
                max_concurrency=_default_concurrency,
                gpu_memory_utilization=gmu,
                max_model_len=8192,
            )
            print("[INFO] âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
            
            # æ„é€ æå°å›¾åƒè¿›è¡Œä¸€æ¬¡è½»é‡ç”Ÿæˆä»¥è§¦å‘å›¾æ•è·ä¸ç¼“å­˜
            print("[INFO] æ­£åœ¨é¢„çƒ­æ¨ç†å¼•æ“...")
            from PIL import Image as _Image
            img = _Image.new("RGB", (64, 64), color=(255, 255, 255))
            proc = DeepseekOCRProcessor(image_size=640, base_size=1024)
            image_features = proc.tokenize_with_images(images=[img], bos=True, eos=True, cropping=False)
            cache_item = {"prompt": "<image>\nWarmup.", "multi_modal_data": {"image": image_features}}
            sp = SamplingParams(temperature=0.0, max_tokens=16, skip_special_tokens=True)
            llm_local.generate([cache_item], sampling_params=sp)
            
            print("=" * 50)
            print("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆï¼ŒæœåŠ¡å³å°†å¯åŠ¨ï¼")
            print("=" * 50)
        except Exception as e:
            print(f"[WARN] âš ï¸ æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")
            print("[INFO] æœåŠ¡å°†ç»§ç»­å¯åŠ¨ï¼Œé¦–æ¬¡æ¨ç†æ—¶ä¼šåŠ è½½æ¨¡å‹")

    warmup_engine_on_start()
    demo, custom_css = create_demo()
    port = int(os.environ.get("DEMO_PORT", "7860"))
    demo.launch(
        server_name="0.0.0.0",
        server_port=port,
        share=False,
        debug=True,
        css=custom_css,
    )
